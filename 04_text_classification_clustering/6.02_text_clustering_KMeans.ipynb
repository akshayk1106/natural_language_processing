{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"Simple example with Cats and Mouse\n",
    "Another simple example with dogs and cats\n",
    "Further simple example with mouse and cheese\"\"\".split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Simple example with Cats and Mouse',\n",
       " 'Another simple example with dogs and cats',\n",
       " 'Further simple example with mouse and cheese']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'example', 'mouse', 'cats', 'and', 'further', 'another', 'dogs', 'simple', 'with', 'cheese'}\n",
      "{'example': 0, 'mouse': 0, 'cats': 0, 'and': 0, 'further': 0, 'another': 0, 'dogs': 0, 'simple': 0, 'with': 0, 'cheese': 0}\n",
      "{'example': 1, 'mouse': 1, 'cats': 1, 'and': 1, 'further': 0, 'another': 0, 'dogs': 0, 'simple': 1, 'with': 1, 'cheese': 0}\n"
     ]
    }
   ],
   "source": [
    "# clearing and tokenizing\n",
    "l_A = corpus[0].lower().split()\n",
    "l_B = corpus[1].lower().split()\n",
    "l_C = corpus[2].lower().split()\n",
    "\n",
    "# Calculating bag of words\n",
    "word_set = set(l_A).union(set(l_B)).union(set(l_C))\n",
    "print(word_set)\n",
    "\n",
    "word_dict_A = dict.fromkeys(word_set, 0)\n",
    "print(word_dict_A)\n",
    "word_dict_B = dict.fromkeys(word_set, 0)\n",
    "word_dict_C = dict.fromkeys(word_set, 0)\n",
    "\n",
    "for word in l_A:\n",
    "    word_dict_A[word] += 1\n",
    "print(word_dict_A)\n",
    "    \n",
    "for word in l_B:\n",
    "    word_dict_B[word] += 1\n",
    "\n",
    "for word in l_C:\n",
    "    word_dict_C[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example': 1,\n",
       " 'mouse': 1,\n",
       " 'cats': 1,\n",
       " 'and': 1,\n",
       " 'further': 0,\n",
       " 'another': 0,\n",
       " 'dogs': 0,\n",
       " 'simple': 1,\n",
       " 'with': 1,\n",
       " 'cheese': 0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf(word_dict, l):\n",
    "    tf = {}\n",
    "    sum_nk = len(l)\n",
    "    for word, count in word_dict.items():\n",
    "        tf[word] = count/sum_nk\n",
    "    return tf\n",
    "  \n",
    "tf_A = compute_tf(word_dict_A, l_A)\n",
    "tf_B = compute_tf(word_dict_B, l_B)\n",
    "tf_C = compute_tf(word_dict_C, l_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example': 0.16666666666666666,\n",
       " 'mouse': 0.16666666666666666,\n",
       " 'cats': 0.16666666666666666,\n",
       " 'and': 0.16666666666666666,\n",
       " 'further': 0.0,\n",
       " 'another': 0.0,\n",
       " 'dogs': 0.0,\n",
       " 'simple': 0.16666666666666666,\n",
       " 'with': 0.16666666666666666,\n",
       " 'cheese': 0.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example': 0.0,\n",
       " 'mouse': 0.4054651081081644,\n",
       " 'cats': 0.4054651081081644,\n",
       " 'and': 0.0,\n",
       " 'further': 1.0986122886681098,\n",
       " 'another': 1.0986122886681098,\n",
       " 'dogs': 1.0986122886681098,\n",
       " 'simple': 0.0,\n",
       " 'with': 0.0,\n",
       " 'cheese': 1.0986122886681098}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_idf(strings_list):\n",
    "    n = len(strings_list)\n",
    "    idf = dict.fromkeys(strings_list[0].keys(), 0)\n",
    "    for l in strings_list:\n",
    "        for word, count in l.items():\n",
    "            if count > 0:\n",
    "                idf[word] += 1\n",
    "    \n",
    "    for word, v in idf.items():\n",
    "        idf[word] = np.log(n / float(v))\n",
    "    return idf\n",
    "    \n",
    "idf = compute_idf([word_dict_A, word_dict_B, word_dict_C])\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf_idf(tf, idf):\n",
    "    tf_idf = dict.fromkeys(tf.keys(), 0)\n",
    "    for word, v in tf.items():\n",
    "        tf_idf[word] = v * idf[word]\n",
    "    return tf_idf\n",
    "    \n",
    "tf_idf_A = compute_tf_idf(tf_A, idf)\n",
    "tf_idf_B = compute_tf_idf(tf_B, idf)\n",
    "tf_idf_C = compute_tf_idf(tf_C, idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example': 0.0,\n",
       " 'mouse': 0.06757751801802739,\n",
       " 'cats': 0.06757751801802739,\n",
       " 'and': 0.0,\n",
       " 'further': 0.0,\n",
       " 'another': 0.0,\n",
       " 'dogs': 0.0,\n",
       " 'simple': 0.0,\n",
       " 'with': 0.0,\n",
       " 'cheese': 0.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "all_text  =  \"\"\"\n",
    "Google and Facebook are strangling the free press to death. Democracy is the loserGoogle an \n",
    "Your 60-second guide to security stuff Google touted today at Next '18\n",
    "A Guide to Using Android Without Selling Your Soul to Google\n",
    "Review: Lenovo’s Google Smart Display is pretty and intelligent\n",
    "Google Maps user spots mysterious object submerged off the coast of Greece - and no-one knows what it is\n",
    "Android is better than IOS\n",
    "In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency\n",
    "is a numerical statistic that is intended to reflect\n",
    "how important a word is to a document in a collection or corpus.\n",
    "It is often used as a weighting factor in searches of information retrieval\n",
    "text mining, and user modeling. The tf-idf value increases proportionally\n",
    "to the number of times a word appears in the document\n",
    "and is offset by the frequency of the word in the corpus\n",
    "\"\"\".split(\"\\n\")[1:-1]\n",
    "\n",
    "# Preprocessing and tokenizing\n",
    "def preprocessing(line):\n",
    "    line = line.lower()\n",
    "    line = re.sub(r\"[{}]\", \" \", line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<13x94 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 141 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(preprocessor=preprocessing)\n",
    "tfidf = tfidf_vectorizer.fit_transform(all_text)\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4).fit(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lines_for_predicting the cluster for given texts\n",
    "lines_for_predicting = [\"tf and idf is awesome!\", \"Selling Your Soul to Google\"]\n",
    "kmeans.predict(tfidf_vectorizer.transform(lines_for_predicting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
