{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark> POS tagging\n",
    "\n",
    "Part of Speech tagging (or PoS tagging) is a process that assigns parts of speech (or words) to each word in a sentence. For example, the tag “Noun” would be assigned to nouns.\n",
    "\n",
    "The basic idea behind Part-of-speech tagging is that different parts of speech have syntactic rules associated with them: verbs change depending on tense, subjects replace pronouns, determiners like ‘a’ or ’the’ don’t show up after certain prepositions, etc. By assigning tags for every word in language content, one can create more specific machine learning models and rephrase sentences according to data inputs from text mining software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words is :  Then\n",
      "POS is   :  ADV === adverb\n",
      "Dep is   :  advmod === adverbial modifier\n",
      "Tag is   :  RB === adverb\n",
      "-----------------------\n",
      "Words is :  the\n",
      "POS is   :  DET === determiner\n",
      "Dep is   :  det === determiner\n",
      "Tag is   :  DT === determiner\n",
      "-----------------------\n",
      "Words is :  Queen\n",
      "POS is   :  PROPN === proper noun\n",
      "Dep is   :  nsubj === nominal subject\n",
      "Tag is   :  NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is :  grew\n",
      "POS is   :  VERB === verb\n",
      "Dep is   :  ROOT === root\n",
      "Tag is   :  VBD === verb, past tense\n",
      "-----------------------\n",
      "Words is :  terribly\n",
      "POS is   :  ADV === adverb\n",
      "Dep is   :  advmod === adverbial modifier\n",
      "Tag is   :  RB === adverb\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp('''Then the Queen grew terribly jealous of Snow White and thought and thought how she could get rid of her, till at last she went to a hunter and engaged him for a large sum of money to take Snow White out into the forest and there kill her and bring back her heart.\n",
    "But when the hunter had taken Snow White out into the forest and thought to kill her, she was so beautiful that his heart failed him, and he let her go, telling her she must not, for his sake and for her own, return to the King's palace. \n",
    "Then he killed a deer and took back the heart to the Queen, telling her that it was the heart of Snow White.\n",
    "Snow White wandered on and on till she got through the forest and came to a mountain hut and knocked at the door, but she got no reply. She was so tired that she lifted up the latch and walked in, and there she saw three little beds and three little chairs and three little cupboards all ready for use. \n",
    "''')\n",
    "\n",
    "for token in doc1[:5]:\n",
    "    print('Words is : ' , token.text)\n",
    "    print('POS is   : ' , token.pos_  , '===', spacy.explain(token.pos_))\n",
    "    print('Dep is   : ' , token.dep_, '===', spacy.explain(token.dep_))\n",
    "    print('Tag is   : ' , token.tag_, '===', spacy.explain(token.tag_))\n",
    "    print('-----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thought    VERB     VBD    verb, past tense\n",
      "and        CCONJ    CC     conjunction, coordinating\n",
      "thought    VERB     VBD    verb, past tense\n",
      "how        SCONJ    WRB    wh-adverb\n",
      "she        PRON     PRP    pronoun, personal\n"
     ]
    }
   ],
   "source": [
    "for token in doc1[10:15]:\n",
    "    print(f'{token.text:{10}} {token.pos_:{8}} {token.tag_:{6}} {spacy.explain(token.tag_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84. ADJ  : 10\n",
      "85. ADP  : 21\n",
      "86. ADV  : 12\n",
      "87. AUX  : 7\n",
      "89. CCONJ: 18\n",
      "90. DET  : 16\n",
      "92. NOUN : 23\n",
      "93. NUM  : 3\n",
      "94. PART : 4\n",
      "95. PRON : 24\n",
      "96. PROPN: 13\n",
      "97. PUNCT: 14\n",
      "98. SCONJ: 7\n",
      "100. VERB : 28\n",
      "103. SPACE: 4\n"
     ]
    }
   ],
   "source": [
    "POS_counts = doc1.count_by(spacy.attrs.POS)\n",
    "\n",
    "for k,v in sorted(POS_counts.items()):\n",
    "    print(f'{k}. {doc1.vocab[k].text:{5}}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74. POS : 1\n",
      "164681854541413346. RB  : 13\n",
      "783433942507015291. NNS : 3\n",
      "1292078113972184607. IN  : 23\n",
      "1534113631682161808. VBG : 2\n",
      "2593208677638477497. ,   : 9\n",
      "3822385049556375858. VBN : 3\n",
      "4062917326063685704. PRP$: 4\n",
      "5595707737748328492. TO  : 2\n",
      "6860118812490040284. RP  : 3\n",
      "6893682062797376370. _SP : 4\n",
      "8427216679587749980. CD  : 3\n",
      "10554686591937588953. JJ  : 10\n",
      "12646065887601541794. .   : 5\n",
      "13656873538139661788. PRP : 20\n",
      "14200088355797579614. VB  : 7\n",
      "15267657372422890137. DT  : 16\n",
      "15308085513773655218. NN  : 20\n",
      "15794550382381185553. NNP : 13\n",
      "16235386156175103506. MD  : 2\n",
      "17109001835818727656. VBD : 21\n",
      "17524233984504158541. WRB : 2\n",
      "17571114184892886314. CC  : 18\n"
     ]
    }
   ],
   "source": [
    "TAG_counts = doc1.count_by(spacy.attrs.TAG)\n",
    "\n",
    "for k,v in sorted(TAG_counts.items()):\n",
    "    print(f'{k}. {doc1.vocab[k].text:{4}}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.     : 9\n",
      "399. advcl: 1\n",
      "400. advmod: 2\n",
      "402. amod: 7\n",
      "403. appos: 2\n",
      "405. aux : 1\n",
      "406. auxpass: 2\n",
      "407. cc  : 3\n",
      "410. conj: 3\n",
      "415. det : 8\n",
      "416. dobj: 6\n",
      "428. npadvmod: 2\n",
      "429. nsubj: 4\n",
      "430. nsubjpass: 3\n",
      "438. pcomp: 1\n",
      "439. pobj: 14\n",
      "440. poss: 3\n",
      "443. prep: 16\n",
      "445. punct: 13\n",
      "447. relcl: 2\n",
      "450. xcomp: 1\n",
      "7037928807040764755. compound: 9\n",
      "8206900633647566924. ROOT: 4\n"
     ]
    }
   ],
   "source": [
    "DEP_counts = doc1.count_by(spacy.attrs.DEP)\n",
    "\n",
    "for k,v in sorted(DEP_counts.items()):\n",
    "    print(f'{k}. {doc1.vocab[k].text:{4}}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word : (Himalaya), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (is), type : (VBZ) , means :  (verb, 3rd person singular present)\n",
      "word : (separating), type : (VBG) , means :  (verb, gerund or present participle)\n",
      "word : (the), type : (DT) , means :  (determiner)\n",
      "word : (plains), type : (NNS) , means :  (noun, plural)\n",
      "word : (of), type : (IN) , means :  (conjunction, subordinating or preposition)\n",
      "word : (the), type : (DT) , means :  (determiner)\n",
      "word : (Indian), type : (JJ) , means :  (adjective (English), other noun-modifier (Chinese))\n",
      "word : (subcontinent), type : (NN) , means :  (noun, singular or mass)\n",
      "word : (from), type : (IN) , means :  (conjunction, subordinating or preposition)\n",
      "word : (the), type : (DT) , means :  (determiner)\n",
      "word : (Tibetan), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (Plateau), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (.), type : (.) , means :  (punctuation mark, sentence closer)\n"
     ]
    }
   ],
   "source": [
    "text = ' Himalaya is separating the plains of the Indian subcontinent from the Tibetan Plateau.'\n",
    "tags = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "\n",
    "for w , m in tags:\n",
    "    print(f'word : ({w}), type : ({m}) , means :  ({spacy.explain(m)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = '''\n",
    "Mount Everest is Earth's highest mountain above sea level, \n",
    "located in the Mahalangur Himal sub-range of the Himalayas. \n",
    "The China–Nepal border runs across its summit point. \n",
    "Its elevation of 8,848.86 m was most recently established in 2020 by the Chinese and Nepali authorities.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\nMount Everest is Earth's highest mountain above sea level, \\nlocated in the Mahalangur Himal sub-range of the Himalayas.\",\n",
       " 'The China–Nepal border runs across its summit point.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_sent_tokenizer = PunktSentenceTokenizer(text)\n",
    "tokenized = custom_sent_tokenizer.tokenize(text)\n",
    "tokenized[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word : (Mount), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (Everest), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (is), type : (VBZ) , means :  (verb, 3rd person singular present)\n",
      "word : (Earth), type : (NNP) , means :  (noun, proper singular)\n",
      "word : ('s), type : (POS) , means :  (possessive ending)\n",
      "word : (highest), type : (JJS) , means :  (adjective, superlative)\n",
      "word : (mountain), type : (NN) , means :  (noun, singular or mass)\n",
      "word : (above), type : (IN) , means :  (conjunction, subordinating or preposition)\n",
      "word : (sea), type : (NN) , means :  (noun, singular or mass)\n",
      "word : (level), type : (NN) , means :  (noun, singular or mass)\n",
      "word : (,), type : (,) , means :  (punctuation mark, comma)\n",
      "word : (located), type : (VBN) , means :  (verb, past participle)\n",
      "word : (in), type : (IN) , means :  (conjunction, subordinating or preposition)\n",
      "word : (the), type : (DT) , means :  (determiner)\n",
      "word : (Mahalangur), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (Himal), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (sub-range), type : (NN) , means :  (noun, singular or mass)\n",
      "word : (of), type : (IN) , means :  (conjunction, subordinating or preposition)\n",
      "word : (the), type : (DT) , means :  (determiner)\n",
      "word : (Himalayas), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (.), type : (.) , means :  (punctuation mark, sentence closer)\n"
     ]
    }
   ],
   "source": [
    "for i in tokenized[:1]:\n",
    "    for w , m in nltk.pos_tag(nltk.word_tokenize(i)):\n",
    "        print(f'word : ({w}), type : ({m}) , means :  ({spacy.explain(m)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re           \n",
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"PRESIDENT GEORGE W. BUSH'S ADDRESS BEFORE A JOINT SESSION OF THE CONGRESS ON THE STATE OF THE UNION\\n \\nFebruary 2, 2005\\n\\n\\n9:10 P.M. EST \\n\\nTHE PRESIDENT: Mr. Speaker, Vice President Cheney, members of Congress, fellow citizens: \\n\\nAs a new Congress gathers, all of us in the elected branches of governme\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"PRESIDENT GEORGE W. BUSH'S ADDRESS BEFORE A JOINT SESSION OF THE CONGRESS ON THE STATE OF THE UNION\\n \\nJanuary 31, 2006\\n\\nTHE PRESIDENT: Thank you all.\",\n",
       " 'Mr. Speaker, Vice President Cheney, members of Congress, members of the Supreme Court and diplomatic corps, distinguished guests, and fellow citizens: Today our nation lost a beloved, graceful, courageous woman who called America to its founding ideals and carried on a noble dream.',\n",
       " 'Tonight we are comforted by the hope of a glad reunion with the husband who was taken so long ago, and we are grateful for the good life of Coretta Scott King.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_sent_tokenizer = PunktSentenceTokenizer(sample_text)\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)\n",
    "tokenized[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word : (PRESIDENT), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (GEORGE), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (W.), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (BUSH), type : (NNP) , means :  (noun, proper singular)\n",
      "word : ('S), type : (POS) , means :  (possessive ending)\n",
      "word : (ADDRESS), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (BEFORE), type : (IN) , means :  (conjunction, subordinating or preposition)\n",
      "word : (A), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (JOINT), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (SESSION), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (OF), type : (IN) , means :  (conjunction, subordinating or preposition)\n",
      "word : (THE), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (CONGRESS), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (ON), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (THE), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (STATE), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (OF), type : (IN) , means :  (conjunction, subordinating or preposition)\n",
      "word : (THE), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (UNION), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (January), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (31), type : (CD) , means :  (cardinal number)\n",
      "word : (,), type : (,) , means :  (punctuation mark, comma)\n",
      "word : (2006), type : (CD) , means :  (cardinal number)\n",
      "word : (THE), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (PRESIDENT), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (:), type : (:) , means :  (punctuation mark, colon or ellipsis)\n",
      "word : (Thank), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (you), type : (PRP) , means :  (pronoun, personal)\n",
      "word : (all), type : (DT) , means :  (determiner)\n",
      "word : (.), type : (.) , means :  (punctuation mark, sentence closer)\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in tokenized[:1]:\n",
    "    for w , m in nltk.pos_tag(nltk.word_tokenize(i)):\n",
    "        print(f'word : ({w}), type : ({m}) , means :  ({spacy.explain(m)})')\n",
    "    print('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
