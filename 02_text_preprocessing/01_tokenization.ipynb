{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark> Tokenisation Using Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Any', 'Config', 'Dict', 'Errors', 'Iterable', 'Language', 'Path', 'Union', 'Vocab', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', 'about', 'attrs', 'blank', 'cli', 'compat', 'displacy', 'errors', 'explain', 'git_info', 'glossary', 'info', 'kb', 'lang', 'language', 'lexeme', 'load', 'logger', 'lookups', 'matcher', 'ml', 'morphology', 'parts_of_speech', 'pipe_analysis', 'pipeline', 'prefer_gpu', 'registry', 'require_cpu', 'require_gpu', 'schemas', 'scorer', 'setup_default_warnings', 'strings', 'symbols', 'sys', 'tokenizer', 'tokens', 'training', 'ty', 'util', 'vectors', 'vocab']\n"
     ]
    }
   ],
   "source": [
    "print(dir(spacy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa_text = '''National Aeronautics and Space Administration is an independent agency of \n",
    "the U.S. federal government responsible for the civil space program, aeronautics research, \n",
    "and space research.\n",
    "'''\n",
    "\n",
    "doc2 = nlp(nasa_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "print(len(nasa_text))\n",
    "print(len(doc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(National, Aeronautics, and, Space, Administration)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[0] , doc2[1] , doc2[2] , doc2[3] , doc2[4] , "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "civil space program, aeronautics research, \n",
      "and\n"
     ]
    }
   ],
   "source": [
    "quote = doc2[18:27]\n",
    "print(quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "National\n",
      "Xxxxx\n",
      "True\n",
      "False\n",
      "---------------\n",
      "Aeronautics\n",
      "Xxxxx\n",
      "True\n",
      "False\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "for token in doc2[:2]:\n",
    "    print(token.text)\n",
    "    # print(token.shape)\n",
    "    print(token.shape_)\n",
    "    print(token.is_alpha)\n",
    "    print(token.is_stop)\n",
    "    print('---------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "National | Aeronautics | and | Space | Administration | is | an | independent | agency | of | \n",
      " | the | U.S. | federal | government | responsible | for | the | civil | space | program | , | aeronautics | research | , | \n",
      " | and | space | research | . | \n",
      " | "
     ]
    }
   ],
   "source": [
    "for token in doc2:\n",
    "    print(token.text, end=' | ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark> Tokenisation Using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import  word_tokenize\n",
    "\n",
    "moon_text = \"\"\"The Moon is Earth's only natural satellite. \n",
    "Its diameter is about one-quarter of Earth's, \n",
    "making it the fifth largest satellite in the Solar System.\n",
    "It is larger than all known dwarf planets in the Solar System.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Moon', 'is', 'Earth', \"'s\", 'only', 'natural', 'satellite', '.', 'Its', 'diameter', 'is', 'about', 'one-quarter', 'of', 'Earth', \"'s\", ',', 'making', 'it', 'the', 'fifth', 'largest', 'satellite', 'in', 'the', 'Solar', 'System', '.', 'It', 'is', 'larger', 'than', 'all', 'known', 'dwarf', 'planets', 'in', 'the', 'Solar', 'System', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(moon_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Moon', 'is', \"Earth's\", 'only', 'natural', 'satellite.']\n",
      "------------------------\n",
      "['The', 'Moon', 'is', 'Earth', \"'s\", 'only', 'natural', 'satellite', '.']\n",
      "====================================================\n",
      "['Its', 'diameter', 'is', 'about', 'one-quarter', 'of', \"Earth's,\"]\n",
      "------------------------\n",
      "['Its', 'diameter', 'is', 'about', 'one-quarter', 'of', 'Earth', \"'s\", ',']\n",
      "====================================================\n"
     ]
    }
   ],
   "source": [
    "for line in moon_text.split('\\n')[:2] :\n",
    "    print(line.split()[:10])\n",
    "    print('------------------------')\n",
    "    print(word_tokenize(line)[:10])\n",
    "    print('====================================================')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
