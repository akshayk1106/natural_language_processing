{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark> Word Embeddings\n",
    "\n",
    "    Word Embeddings in NLP is a technique where individual words are represented as real-valued vectors in a lower-dimensional space and captures inter-word semantics.\n",
    "    Word Embedding or Word Vector is a numeric vector input that represents a word in a lower-dimensional space. It allows words with similar meaning to have a similar representation.\n",
    "    They can also approximate meaning. A word vector with 50 values can represent 50 unique features.\n",
    "    \n",
    "Advantages:\n",
    "       \n",
    "    Gives real valued vectors in a lower dimensional space\n",
    "    Captures inter word semantics\n",
    "    Reduces dimentionality\n",
    "    Helps predict words around a word\n",
    "    Methods such as BoW, TD-IDF rely on the word count in a sentence but they do not save any semantic info.\n",
    "    Almost all modern nlp applications start with embedding layer\n",
    "    \n",
    "Disadvantages:\n",
    "    \n",
    "    memory intensive\n",
    "    cannot distinguish between homophones. eg., brake/break\n",
    "    \n",
    "Approaches/Techniques\n",
    "    \n",
    "    Word2Vec\n",
    "        cbow\n",
    "        skip-gram\n",
    "    GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.1729e-01,  1.3588e+00, -4.9205e-02,  1.5158e+00,  1.3116e+00,\n",
       "       -2.1567e+00,  3.6357e+00,  1.8520e+00, -5.0275e+00,  2.1978e+00,\n",
       "        7.0311e+00,  1.5903e+00, -4.3006e+00,  2.3341e+00,  3.9661e+00,\n",
       "       -7.5158e-01,  2.3964e+00, -1.1702e+00, -2.1844e-02, -1.7807e-01,\n",
       "       -2.1027e+00,  3.0961e+00, -7.9090e-03, -2.0693e-01, -2.9393e+00,\n",
       "       -1.2823e+00,  1.5543e-02,  9.5328e-01, -3.2584e+00,  3.7656e+00,\n",
       "       -5.0492e-01, -3.7038e+00,  8.3301e-01, -1.7658e+00,  2.6687e+00,\n",
       "       -2.5927e+00,  1.3625e+00,  1.1390e+00,  3.7002e+00,  1.7027e+00,\n",
       "        3.2552e+00, -2.4619e+00, -1.7036e+00, -3.1906e+00, -5.6705e-01,\n",
       "        4.0653e+00,  5.0637e+00, -4.4248e+00, -2.4892e+00,  1.8204e+00,\n",
       "       -1.2794e-02,  9.8560e-02,  3.9811e-01, -3.5691e+00, -3.4484e+00,\n",
       "        1.6158e+00,  4.5479e+00,  6.7522e+00,  2.9260e-01,  8.7796e-01,\n",
       "        2.5872e+00,  7.0159e-01, -1.2507e+00, -1.2619e+00, -1.5277e+00,\n",
       "        3.1918e+00, -2.2707e+00, -9.8390e+00,  6.5251e-02, -3.0916e-01,\n",
       "       -2.4709e+00,  3.6871e+00, -1.0371e+00,  2.6193e+00, -4.9801e-01,\n",
       "        2.2413e+00, -1.6800e+00,  1.5356e+00, -3.5054e-01, -2.3575e-01,\n",
       "       -5.5008e+00, -2.8019e+00, -9.2825e-01, -1.2990e+00,  8.7035e-01,\n",
       "        1.0052e+00,  4.0218e-01,  3.6715e+00,  5.9672e-01,  2.1549e+00,\n",
       "       -6.9606e-01,  6.7729e+00,  1.0382e+00, -5.1648e+00, -7.7544e-01,\n",
       "       -5.0898e-01,  4.8254e+00,  3.5454e-01, -2.1682e-01, -3.7372e+00,\n",
       "        2.3668e+00, -1.7620e-01,  1.9225e+00,  5.6415e+00, -3.6483e+00,\n",
       "        5.0037e+00, -3.3074e+00, -4.2098e-01,  5.2183e-01,  2.0789e+00,\n",
       "        1.6895e+00, -2.8723e+00, -1.1922e+00,  1.0336e+00, -1.2719e+00,\n",
       "        5.0928e+00, -3.5244e+00, -1.1785e+00, -1.8721e-01, -1.3711e+00,\n",
       "       -3.8066e+00,  1.0573e-01, -2.4441e+00,  3.1518e+00, -2.1114e+00,\n",
       "       -1.8572e+00, -1.8855e+00, -7.2911e+00,  3.4562e+00,  5.8180e-01,\n",
       "       -4.7655e+00,  2.1524e+00,  6.4540e-01, -1.6410e-01, -2.6053e+00,\n",
       "       -6.5690e-01,  2.3612e+00, -3.6739e+00,  2.5199e+00, -1.1633e+00,\n",
       "       -3.7649e-01, -9.7144e-02, -8.3204e-01, -5.8694e-01, -1.6235e-02,\n",
       "       -1.3468e+00,  8.4638e-01,  1.2842e+00, -5.8283e-01,  2.9471e+00,\n",
       "       -3.4723e+00,  2.9403e+00,  1.0824e+00,  1.1259e-01,  2.5542e-01,\n",
       "       -3.8694e-01,  5.0242e+00, -2.0178e+00, -1.7016e+00, -3.5864e+00,\n",
       "        6.1822e-01,  1.2605e-01,  1.9488e+00, -2.7509e-01, -1.6305e+00,\n",
       "        3.8501e-01, -2.3038e+00,  2.5354e+00, -2.4739e+00, -5.4513e-01,\n",
       "        3.4292e+00,  9.6842e-01, -9.4609e-01,  2.2563e+00,  1.6973e+00,\n",
       "       -1.8876e+00, -3.6616e-01,  3.2028e+00, -9.4827e-01, -1.4736e+00,\n",
       "        9.8314e-01,  2.8488e+00,  4.3292e+00, -4.9792e+00,  1.1779e+00,\n",
       "       -1.8140e+00, -6.9600e+00, -5.5218e+00, -9.7505e-02,  3.3065e+00,\n",
       "       -1.7994e+00,  7.9182e-01, -4.6457e+00, -5.6926e-02,  3.2511e-01,\n",
       "        1.8305e+00, -1.6192e+00, -3.4247e+00,  3.3305e+00, -1.4247e+00,\n",
       "       -3.4368e+00, -5.4543e-01, -3.9328e+00, -2.7862e+00,  3.1293e-01,\n",
       "       -1.8692e-01, -5.3591e+00,  1.4669e+00,  3.5998e+00, -1.3430e+00,\n",
       "        2.1757e+00,  2.0454e+00,  8.8196e-01,  2.3198e+00, -1.0956e+00,\n",
       "        2.7940e+00,  5.1417e+00, -1.4032e+00, -3.6823e+00,  3.5298e+00,\n",
       "       -2.6991e+00,  3.3062e+00, -2.2702e+00,  1.9619e+00,  1.0436e+00,\n",
       "       -6.1978e-01,  7.5253e-01,  7.3662e-01,  5.8717e+00, -2.5266e+00,\n",
       "       -2.1770e+00, -2.0912e+00,  3.2092e+00, -1.8627e+00,  2.0986e+00,\n",
       "        2.0570e-01, -1.1568e+00, -1.9063e-01,  1.3789e+00,  4.8775e+00,\n",
       "       -1.5359e-01, -1.7890e+00, -1.4656e+00,  3.1835e+00,  9.1214e-01,\n",
       "       -2.0247e-01, -2.1733e+00,  7.7180e-02, -2.0341e+00,  1.8835e+00,\n",
       "       -3.2268e+00,  1.5975e+00, -7.1260e+00, -2.6081e+00,  2.5685e-01,\n",
       "       -2.4025e+00,  2.2341e+00,  1.4352e+00, -7.6942e-01,  6.5105e-02,\n",
       "       -2.4077e+00,  5.3812e+00,  1.2884e-01,  3.0489e-01, -9.0988e-01,\n",
       "        2.2973e+00, -1.1720e+00,  6.7633e+00, -4.0698e+00, -3.5966e+00,\n",
       "        3.4586e+00, -8.2568e-01,  1.9597e+00,  8.7034e-01, -1.9004e-01,\n",
       "       -2.6882e+00,  8.8935e-01, -5.8699e-01, -2.5409e+00,  3.7010e+00,\n",
       "        4.1583e+00, -4.1597e+00, -1.7678e+00,  2.6213e+00,  3.8440e+00,\n",
       "       -7.1880e-01,  7.2957e-01, -1.1422e+00,  1.5506e+00,  2.6622e+00,\n",
       "        2.0343e+00, -1.5269e+00,  5.0924e-01, -1.8634e+00,  2.7435e+00,\n",
       "        2.2392e+00,  2.4743e+00,  6.2737e-01, -5.5825e+00, -8.1358e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'simple').vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.167    ,  0.29991  , -3.1277   , -2.7817   , -0.26743  ,\n",
       "        3.0804   , -2.6528   ,  0.59692  ,  0.12359  ,  4.8586   ,\n",
       "        5.9099   , -5.0363   , -0.92574  ,  0.24834  ,  0.99726  ,\n",
       "       -1.4138   , -1.6813   , -2.3217   ,  2.239    , -2.406    ,\n",
       "       -3.1548   , -0.31535  ,  0.63494  ,  2.6102   ,  0.029033 ,\n",
       "        0.36093  ,  0.82687  , -0.046114 ,  0.86223  , -1.539    ,\n",
       "       -1.3586   , -4.2778   ,  0.92605  , -3.623    , -0.20905  ,\n",
       "        0.40445  , -0.51169  , -0.18221  , -0.45019  ,  1.6452   ,\n",
       "       -0.21377  , -0.013464 ,  1.3225   ,  2.6444   ,  2.8484   ,\n",
       "       -1.8366   , -1.6336   ,  2.3608   ,  1.8614   ,  0.62935  ,\n",
       "       -1.7363   , -1.2249   ,  0.012297 , -0.23621  ,  0.40521  ,\n",
       "       -0.65902  , -2.3748   , -3.9021   ,  0.16969  ,  5.1174   ,\n",
       "       -0.60783  , -3.2307   ,  2.2142   , -0.09337  , -0.64347  ,\n",
       "       -2.0623   , -3.5153   , -3.5514   ,  3.1468   ,  2.199    ,\n",
       "       -1.9324   ,  1.7778   , -0.98875  , -3.8789   , -1.6005   ,\n",
       "        3.1626   , -0.85008  ,  4.248    ,  1.3081   ,  5.5981   ,\n",
       "       -2.3599   , -1.4777   ,  0.070376 , -2.6391   ,  1.8811   ,\n",
       "       -0.32252  ,  1.0728   ,  3.1274   , -2.8972   , -1.4292   ,\n",
       "        0.97709  ,  0.24257  ,  3.176    , -1.7642   , -4.3298   ,\n",
       "        1.0399   ,  3.9173   ,  1.5171   , -1.6307   , -1.3717   ,\n",
       "       -2.2272   ,  2.2516   ,  0.87128  ,  1.6893   ,  0.36115  ,\n",
       "       -0.24849  , -2.1259   ,  5.6562   ,  0.44488  , -0.65038  ,\n",
       "       -3.7956   ,  5.6118   ,  1.6489   , -2.5152   ,  6.4116   ,\n",
       "       -2.7203   , -2.4978   , -2.4328   ,  0.79147  , -2.1373   ,\n",
       "        0.1531   , -0.11298  , -0.019034 , -1.8828   , -0.39994  ,\n",
       "       -4.7997   , -0.31418  , -4.2527   , -1.4356   ,  1.9432   ,\n",
       "       -0.62276  , -0.19423  , -0.16307  ,  0.077675 ,  0.0097314,\n",
       "       -0.96013  ,  0.38501  , -1.5418   , -1.9436   , -1.6795   ,\n",
       "       -7.9544   ,  0.046187 ,  1.1842   ,  2.9252   , -0.12064  ,\n",
       "       -2.5592   , -3.4564   ,  3.3279   ,  1.4566   , -0.26747  ,\n",
       "       -1.2208   ,  1.5311   ,  2.078    ,  0.97777  , -0.31091  ,\n",
       "        1.5046   , -2.0353   ,  0.32025  , -1.5669   ,  0.82247  ,\n",
       "       -2.0084   , -6.0252   , -4.3223   , -0.88354  , -3.8267   ,\n",
       "       -5.3679   ,  0.04028  , -3.8084   , -1.4745   , -0.54509  ,\n",
       "        4.421    , -3.1668   , -0.063313 ,  1.24     ,  0.49723  ,\n",
       "       -4.7846   , -1.8343   , -1.3872   ,  1.1227   , -1.6363   ,\n",
       "        1.2152   ,  1.3122   ,  0.9896   , -3.2111   ,  0.78302  ,\n",
       "        2.7014   ,  1.1404   ,  0.39821  , -1.5174   ,  1.1302   ,\n",
       "        1.8146   , -2.3713   , -4.4074   ,  0.84996  , -0.89355  ,\n",
       "       -1.0498   ,  1.6979   ,  3.7127   , -2.2946   ,  2.1826   ,\n",
       "        2.7204   , -1.2092   , -2.9457   ,  0.82411  , -6.5106   ,\n",
       "       -3.0997   ,  4.2783   , -1.9091   , -1.5795   ,  1.2377   ,\n",
       "        0.17789  ,  0.59716  ,  1.3507   ,  4.194    , -0.18735  ,\n",
       "        2.221    ,  1.1118   ,  0.37114  ,  0.40229  , -2.2347   ,\n",
       "       -0.60677  , -5.2076   ,  1.6655   ,  7.6159   , -1.8159   ,\n",
       "       -1.99     ,  3.0499   ,  0.0127   ,  0.11955  ,  2.6081   ,\n",
       "       -2.6869   , -0.21315  , -1.5071   ,  1.6894   , -0.061009 ,\n",
       "        2.7747   , -3.9287   , -0.37922  , -1.2262   ,  3.0221   ,\n",
       "        0.42178  ,  5.0441   , -4.9504   , -1.7701   ,  3.5365   ,\n",
       "       -4.2432   ,  1.8922   ,  3.3551   ,  1.1064   ,  1.03     ,\n",
       "        2.5214   , -0.11403  ,  0.72351  ,  1.5749   , -1.1543   ,\n",
       "       -5.0317   ,  4.3374   ,  5.6829   ,  1.5816   , -1.3539   ,\n",
       "        1.2004   , -3.6165   , -1.4561   , -0.40638  , -0.21109  ,\n",
       "       -1.5671   ,  0.26342  , -0.21204  , -6.1106   ,  7.7494   ,\n",
       "        0.20884  , -0.52777  , -7.2462   ,  0.84291  , -0.45407  ,\n",
       "       -1.8387   ,  0.85934  ,  0.061233 , -1.9492   ,  5.4187   ,\n",
       "       -3.3688   , -1.4679   ,  3.1577   ,  1.1711   ,  3.688    ,\n",
       "        0.42717  , -0.14362  ,  2.3758   ,  1.2226   , -2.9312   ,\n",
       "        3.2187   ,  1.6753   ,  0.025952 , -1.2207   ,  0.97648  ,\n",
       "        2.2651   ,  0.30664  ,  2.134    , -7.0684   ,  1.018    ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'queen').vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp(u'queen').vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.25519991e+00,  3.38542414e+00, -3.04648018e+00,  6.03720009e-01,\n",
       "        1.04830003e+00,  4.15392208e+00, -3.96093994e-01,  2.26865983e+00,\n",
       "       -1.46673000e+00, -2.92162001e-01,  4.83446026e+00,  2.30411792e+00,\n",
       "       -2.25753927e+00,  2.27109981e+00,  2.77898598e+00, -1.24686408e+00,\n",
       "        2.15660882e+00, -3.63025212e+00, -5.77811956e-01, -3.85101366e+00,\n",
       "        1.82344282e+00, -1.92588997e+00,  1.15956807e+00, -4.75785971e+00,\n",
       "        1.64125407e+00, -2.13626191e-01, -1.96125603e+00,  4.45760012e-01,\n",
       "       -3.84769857e-01,  7.90479958e-01,  1.83882010e+00, -2.90632010e+00,\n",
       "        4.48359966e-01, -4.07026005e+00, -2.43132997e+00, -2.65275192e+00,\n",
       "       -1.89988804e+00,  1.82103992e+00,  3.42263603e+00, -1.06763005e+00,\n",
       "       -1.17767191e+00,  1.99106193e+00,  1.98964000e+00,  2.58064008e+00,\n",
       "       -5.26899993e-01,  5.61385989e-01, -1.25947988e+00, -4.97865200e+00,\n",
       "       -2.48386002e+00,  3.70113993e+00,  3.46220016e-01,  3.68628001e+00,\n",
       "        6.64319992e-01, -4.70230007e+00,  2.90353954e-01, -3.38275969e-01,\n",
       "       -2.00697988e-01,  2.53211021e+00,  2.08263206e+00,  2.09348011e+00,\n",
       "       -1.06166005e-01, -3.01886010e+00,  9.24655914e-01, -1.71462893e+00,\n",
       "       -1.16071984e-01, -1.73646796e+00, -3.63486028e+00, -4.10884190e+00,\n",
       "        5.00379920e-01,  3.84193993e+00,  1.93236995e+00,  5.08363962e-01,\n",
       "       -1.08455014e+00,  1.41860008e+00,  1.20298398e+00,  2.13290596e+00,\n",
       "       -4.43130016e+00,  2.67648387e+00, -1.73775196e+00, -3.88192606e+00,\n",
       "       -5.25623989e+00, -6.18767977e-01,  2.44077063e+00,  3.24921417e+00,\n",
       "        2.65569806e+00, -5.30002126e-03, -1.34865594e+00, -3.09855986e+00,\n",
       "        3.12965959e-01, -2.85647011e+00, -1.08397400e+00, -3.78330022e-01,\n",
       "        3.83880019e-01, -2.58606386e+00,  2.00704002e+00, -1.74365199e+00,\n",
       "        9.56820130e-01,  1.05385590e+00,  3.09443212e+00,  1.99478060e-01,\n",
       "        2.45043993e+00,  2.20139956e+00,  1.32594013e+00, -2.20340248e-02,\n",
       "        2.19776011e+00,  2.20542407e+00, -3.55628014e+00, -2.12123227e+00,\n",
       "       -7.26755977e-01, -4.68137598e+00,  3.90052021e-01, -1.79793203e+00,\n",
       "       -2.82599986e-01, -3.76421928e-01,  3.21040064e-01,  1.83134007e+00,\n",
       "       -2.99041796e+00, -3.45597982e+00,  4.36485386e+00,  6.65574074e-01,\n",
       "       -1.70738196e+00,  1.62251994e-01, -3.78699803e+00,  9.82519925e-01,\n",
       "       -2.49829817e+00, -4.28600311e-02,  3.23691988e+00, -1.47991180e+00,\n",
       "        3.48614550e+00,  7.20999986e-02, -4.21349812e+00, -3.02658010e+00,\n",
       "        2.98544002e+00, -8.28531921e-01,  7.89219975e-01,  2.47194004e+00,\n",
       "       -2.86876202e+00,  4.07059968e-01,  3.20153189e+00, -3.57890010e+00,\n",
       "       -3.88153195e+00, -3.06895971e+00, -1.66240001e+00,  5.19400120e-01,\n",
       "        7.98455894e-01,  1.92315805e+00, -3.55674028e+00,  4.13349569e-01,\n",
       "        2.50870633e+00, -2.85223603e+00,  1.72376001e+00,  1.78955591e+00,\n",
       "        1.67421794e+00, -2.42734003e+00, -1.19031405e+00,  2.01587987e+00,\n",
       "        2.46004200e+00, -2.56573987e+00, -5.06543827e+00, -1.44032729e+00,\n",
       "       -1.54137206e+00, -3.90514374e+00, -1.31178010e+00,  4.49233949e-01,\n",
       "       -2.89766002e+00, -9.31540012e-01, -1.90881991e+00, -2.35122055e-01,\n",
       "       -2.79396009e+00, -5.45359969e-01,  1.04027998e+00, -7.48578072e-01,\n",
       "        2.44329405e+00,  3.23048258e+00,  1.88514006e+00, -9.35819983e-01,\n",
       "       -1.34610027e-01, -2.13123226e+00, -2.82611990e+00, -3.58378410e+00,\n",
       "       -3.11909974e-01, -1.29610014e+00,  2.58427501e+00, -1.08581400e+00,\n",
       "        5.78857958e-01,  4.08694029e-01, -9.07191932e-01, -2.92430925e+00,\n",
       "        2.93464613e+00,  1.74618185e+00, -1.25023997e+00,  4.56590176e+00,\n",
       "       -3.46916008e+00, -1.50206208e+00, -4.42981625e+00, -2.18288183e+00,\n",
       "       -4.52142000e+00,  3.66176128e-01,  3.35355937e-01,  1.36541593e+00,\n",
       "       -5.24485946e-01, -3.15815020e+00, -2.11900210e+00, -2.82816195e+00,\n",
       "        1.86503983e+00,  4.74690050e-01, -2.77048051e-01,  5.28999791e-02,\n",
       "        3.01854044e-01,  6.96368098e-01,  4.20000076e-01,  1.59536004e+00,\n",
       "       -1.33415592e+00,  1.67229784e+00,  1.94282019e+00,  2.80714607e+00,\n",
       "       -1.10211802e+00, -1.26646399e+00, -2.06185007e+00, -2.11331201e+00,\n",
       "       -2.30133986e+00,  7.30533957e-01,  1.05697989e+00,  2.37029791e+00,\n",
       "       -1.75719392e+00, -6.53980017e-01, -9.19219136e-01,  5.97519994e-01,\n",
       "        4.10604000e+00,  1.81741405e+00, -1.15869975e+00, -4.00472021e+00,\n",
       "       -2.12895608e+00, -1.68896198e+00,  3.22269964e+00,  6.01090074e-01,\n",
       "       -2.89075804e+00,  2.66624403e+00, -1.72142184e+00,  6.90536022e-01,\n",
       "        4.72371966e-01, -8.12600404e-02,  6.46896076e+00, -1.47960782e+00,\n",
       "       -6.76038086e-01,  3.72327995e+00, -5.40962577e-01, -1.29680002e+00,\n",
       "        1.97213399e+00,  9.29959267e-02, -2.12093997e+00, -2.24539399e+00,\n",
       "       -4.62626171e+00,  6.02274835e-01, -6.53023839e-01, -2.60514593e+00,\n",
       "        2.64637995e+00,  2.16836596e+00, -2.89603996e+00,  8.39258015e-01,\n",
       "        2.36685991e+00,  2.73107982e+00,  7.36999869e-01, -3.98692012e-01,\n",
       "        1.87210596e+00, -3.88473964e+00,  5.05904019e-01,  3.51745987e+00,\n",
       "       -3.75517988e+00,  3.02330804e+00, -4.76790249e-01, -2.23656011e+00,\n",
       "       -1.06586790e+00, -2.92587805e+00,  1.48798394e+00, -1.70947397e+00,\n",
       "        1.13861597e+00, -1.08604014e+00, -2.63089180e+00,  2.27916813e+00,\n",
       "       -2.81024599e+00,  6.56502008e-01,  1.87483811e+00,  1.46355605e+00,\n",
       "        3.01963186e+00, -2.57291389e+00, -3.18188024e+00,  4.52146053e+00,\n",
       "       -3.19363809e+00, -3.12301964e-01, -1.01626205e+00, -9.54900011e-02,\n",
       "        1.72902417e+00,  2.47834611e+00, -3.53660011e+00,  7.26916015e-01,\n",
       "       -2.65329981e+00, -9.29319859e-02, -5.13176012e+00,  3.87912005e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "doc = nlp(u'who let the dogs out')\n",
    "print(np.array(doc).shape)\n",
    "doc.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiger \t tiger \t 1.0\n",
      "tiger \t dog \t 0.42287227511405945\n",
      "tiger \t pet \t 0.31030499935150146\n",
      "dog \t tiger \t 0.42287227511405945\n",
      "dog \t dog \t 1.0\n",
      "dog \t pet \t 0.7856058478355408\n",
      "pet \t tiger \t 0.31030499935150146\n",
      "pet \t dog \t 0.7856058478355408\n",
      "pet \t pet \t 1.0\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp(u'tiger dog pet')\n",
    "\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1.text, '\\t', token2.text, '\\t', token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6108841234425123"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'king').similarity(nlp(u'queen'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.210579704017407"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'king').similarity(nlp(u'fish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06449755090975247"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'queen').similarity(nlp(u'photo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity can be checked between sentences also,\n",
    "# notice the similarity score to be high even if the sentences mean totally different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9535042087197989"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'we love pizza').similarity(nlp(u'we hate pizza'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9799502109135215"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'this place is awesome. I love it').similarity(nlp(u'this place is boring. I hate it'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "514157"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.vocab.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(514157, 300)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king True 69.68691 False\n",
      "dgks False 0.0 True\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp(u'king dgks')\n",
    "\n",
    "for token in tokens:\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word queen , has similarity 0.7880843877792358\n",
      "Word prince , has similarity 0.6401076912879944\n",
      "Word princess , has similarity 0.6125636100769043\n",
      "Word elizabeth , has similarity 0.4564860165119171\n",
      "Word crown , has similarity 0.42476341128349304\n",
      "Word castle , has similarity 0.3814162015914917\n",
      "Word white , has similarity 0.32747429609298706\n",
      "Word angry , has similarity 0.2994381785392761\n",
      "Word sea , has similarity 0.2897905111312866\n",
      "Word cat , has similarity 0.27486881613731384\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "cosine_similarity = lambda x, y: 1 - spatial.distance.cosine(x, y)\n",
    "\n",
    "king = nlp.vocab['king'].vector\n",
    "man = nlp.vocab['man'].vector\n",
    "woman = nlp.vocab['woman'].vector\n",
    "\n",
    "# Now we find the closest vector in the vocabulary to the result of \"man\" - \"woman\" + \"queen\"\n",
    "new_vector = king - man + woman\n",
    "computed_similarities = []\n",
    "\n",
    "words = ['cat','apple','queen','castle','sea','shell','orange','phone' , 'tiffany'\n",
    "         ,'angry','book','white','land','study','crown','prince','dog',\n",
    "         'great','princess','elizabeth','wow','eat','dead','horrible']\n",
    "\n",
    "for word in words:\n",
    "    similarity = cosine_similarity(new_vector,nlp.vocab[word].vector)\n",
    "    computed_similarities.append((word, similarity))\n",
    "\n",
    "computed_similarities = sorted(computed_similarities, key=lambda item: -item[1])\n",
    "\n",
    "for a,b in computed_similarities[:10] : \n",
    "    print(f'Word {a} , has similarity {b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
